{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 그래프에 쓰레드 수준의 영속성을 추가하는 방법\n",
    "많은 AI 애플리케이션은 여러 상호작용에서 컨텍스트를 공유하기 위해 메모리를 필요로 함\n",
    "\n",
    "LangGraph에서는 쓰레드 수준의 영속성을 사용하여 이러한 메모리를 모든 StateGraph에 추가할 수 있음\n",
    "- LangGraph 그래프를 생성할 때(그래프를 컴파일할 때) 체크포인터를 추가하여 그래프의 상태를 유지하도록 설정할 수 있음"
   ],
   "id": "89bd1d48f297421c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-29T08:09:47.209724Z",
     "start_time": "2025-04-29T08:09:47.201244Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 그래프 정의\n",
    "채팅 모델을 호출하는 단일 노드 그래프를 사용"
   ],
   "id": "2cf7e7695eb391c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T08:11:09.382535Z",
     "start_time": "2025-04-29T08:11:08.509290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ],
   "id": "f80b6d07362c1e63",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T08:11:40.889674Z",
     "start_time": "2025-04-29T08:11:40.832726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "graph = builder.compile()"
   ],
   "id": "273c0b9d58c4b82a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "이 그래프를 사용하려고 하면 대화의 맥락이 상호 작용 전반에 걸쳐 유지되지 않습니다.",
   "id": "950ff926f2acba5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T08:11:51.053980Z",
     "start_time": "2025-04-29T08:11:48.733503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_message = {\"role\": \"user\", \"content\": \"hi! I'm bob\"}\n",
    "for chunk in graph.stream({\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()\n",
    "\n",
    "input_message = {\"role\": \"user\", \"content\": \"what's my name?\"}\n",
    "for chunk in graph.stream({\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ],
   "id": "26e99236173d3ed2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "hi! I'm bob\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hi Bob! How can I assist you today?\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "what's my name?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "I'm sorry, but I don't have access to personal information about users unless it has been shared with me in the course of our conversation. How can I assist you today?\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 영속성 추가\n",
    "영속성을 추가하려면 그래프를 컴파일 할 때 체크포인터를 전달해야 합니다."
   ],
   "id": "3c3a08792c99537f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T08:14:10.960331Z",
     "start_time": "2025-04-29T08:14:10.948048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "# LangGraph Cloud나 LangGraph Studio를 사용하는 경우, 그래프를 컴파일할 때 checkpointer를 따로 전달할 필요가 없습니다.(자동으로 처리되기 때문입니다.)"
   ],
   "id": "add0e9a1e6dc68c8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T08:14:24.790627Z",
     "start_time": "2025-04-29T08:14:23.524243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "input_message = {\"role\": \"user\", \"content\": \"hi! I'm bob\"}\n",
    "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ],
   "id": "38b8f7503b448361",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "hi! I'm bob\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hi Bob! How can I help you today?\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T08:14:32.794669Z",
     "start_time": "2025-04-29T08:14:32.117608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_message = {\"role\": \"user\", \"content\": \"what's my name?\"}\n",
    "for chunk in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ],
   "id": "d2d4e50caacde2db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "what's my name?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Your name is Bob! What would you like to talk about?\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "새 대화를 시작하고 싶다면, 다른 thread_id를 전달하면 됩니다.",
   "id": "8158e07a089b1d27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T08:15:30.547999Z",
     "start_time": "2025-04-29T08:15:29.121839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_message = {\"role\": \"user\", \"content\": \"what's my name?\"}\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [input_message]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ],
   "id": "31c1949f1638d91d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "what's my name?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "I'm sorry, but I don't have access to personal information about users unless you provide it during our conversation. If you'd like me to address you by a specific name, please let me know!\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
